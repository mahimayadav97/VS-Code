{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sort import *\n",
    "\n",
    "# File path for the video\n",
    "FILE_PATH = \"traffic_video.mp4\"\n",
    "\n",
    "# Class names for YOLO model\n",
    "classNames = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\",\n",
    "    \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "    \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
    "    \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\",\n",
    "    \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\",\n",
    "    \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "    \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# For Tracker\n",
    "tracker = Sort(max_age=20, min_hits=3, iou_threshold=0.3)\n",
    "cap = cv2.VideoCapture(FILE_PATH)\n",
    "model = YOLO(\"yolov81.pt\")\n",
    "\n",
    "# Get video writer initialized to save the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(img, stream=True)\n",
    "    detections = np.empty((0, 5))\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            # Class name\n",
    "            cls = int(box.cls[0])\n",
    "            \n",
    "            # Confidence score\n",
    "            conf = math.ceil(box.conf[0] * 100) / 100\n",
    "            \n",
    "            if conf > 0.5:\n",
    "                cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (x2, y2), scale=1, thickness=1, colorR=(0, 0, 255))\n",
    "                currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currentArray))\n",
    "\n",
    "    resultTracker = tracker.update(detections)\n",
    "\n",
    "    for res in resultTracker:\n",
    "        x1, y1, x2, y2, id = res\n",
    "        x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        cvzone.putTextRect(img, f'ID: {id}', (x1, y1), scale=1, thickness=1, colorR=(0, 0, 255))\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=1, colorR=(255, 0, 255))\n",
    "\n",
    "    out.write(img)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Display the processed video in the notebook\n",
    "from IPython.display import Video\n",
    "Video(\"output_video.mp4\", embed=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
